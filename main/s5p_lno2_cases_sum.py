'''
INPUT:
    - lno2_cases*.csv generated by `s5p_lno2_cases.py`

OUTPUT:
    - fresh_lightning_cases.csv or no_lightning_cases.csv which contains the consecutive fresh_lightning or no_lightning cases
    - ctmana_dates.csv which saves the date(yyymmdd) saved cases
       it can be passed to `download_ctmana.py` to download CTMANA files

UPDATE:
    Xin Zhang:
        2022-07-14: basic version
'''

import logging
import os
from glob import glob
from itertools import groupby
import pandas as pd

from s5p_lno2_utils import Config

logging.basicConfig(level=logging.INFO)


def main():
    # read the lno2 case data
    file_list = glob(output_data_dir+'/lno2_cases_*csv')
    logging.debug(f'    Reading {file_list} ...')

    data = []
    last_value = 0
    
    # Loop through files
    for file in file_list:
        # Read the file into a DataFrame
        df_temp = pd.read_csv(file)
    
        # Continue the last value from the previous file in the current file
        df_temp['case'] += last_value
        last_value = df_temp.iloc[-1]['case'] + 1
    
        # different here: append the data
        data.append(df_temp)
    
    df = pd.concat(data)

    if kind == 'fresh_lightning':
        # for safety, we use at least 10 lightning in the mask to filter convective cases
        df = df[df['fresh_lightning'] > 10].reset_index()
    elif kind == 'no_lightning':
        # this is useful for estimating lightning NO2 lifetime
        
        # create boolean masks which are true when `fresh_lightning` is <=5 and previous `case` is the same
        mask = (df.case.eq(df.case.shift())) & (df['fresh_lightning']<=5)
        
        # concat previous rows and fresh_lightning<=5 rows
        df = pd.concat([df[mask.shift(-1).fillna(False)], df[df['fresh_lightning']<=5]]).sort_values(['case', 'filename'])
        df = df.drop_duplicates(keep='first').reset_index()

    # caculate the difference between indexes
    diff = df['index'].diff().bfill()

    # select at least two consecutive indexes
    #   https://stackoverflow.com/a/71698687/7347925
    df = df.groupby(diff.ne(1).cumsum()).filter(lambda d: len(d) > 1)

    # assign new case No.
    #   https://stackoverflow.com/a/74979132/7347925
    df['case'] = df.groupby('case')['index'].diff().ne(1).cumsum().factorize()[0]

    # clean columns and index
    df = df.reset_index(drop=True)
    df = df.drop(columns=['index'])
    logging.info(df)

    # export data
    savename = output_data_dir + f'/{kind}_cases.csv'
    logging.info(f'Saved the DataFrame to {savename}')
    df.to_csv(savename, index=False)

    # get the basenames of the filelist
    basenames = list(sorted(map(os.path.basename, df['filename'])))

    # get the dates of consecutive swaths for downloading CTMANA files
    dates = []
    for _, g in groupby(enumerate(basenames), lambda k: int(k[1].split('_')[-3]) - k[0]):
        dates.extend([v.split('_')[-5][:8] for _, v in g])

    # export dates for downloading CTMANA files
    dates = list(sorted(set(dates)))
    df_dates = pd.DataFrame(dates, columns=['dates'])
    logging.info(df_dates)
    logging.info(f'Saved the Dates(yyyymmdd) DataFrame to {savename}')
    df_dates.to_csv('ctmana_dates.csv', index=False, header=False)


if __name__ == '__main__':
    # read config file
    cfg = Config('settings.txt')
    output_data_dir = cfg['output_data_dir']

    kind = 'fresh_lightning'  # fresh_lightning or no_lightning

    main()
