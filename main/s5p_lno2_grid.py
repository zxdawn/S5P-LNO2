'''
INPUT:
    - Product file named "S5P_LNO2_production.nc", generated by `s5p_lno2_pe_lifetime.py`

OUTPUT:
    Gridded data: S5P_LNO2_grid.nc
        - variables: lno2, lno2_max, lno2_sum, lightning, and lightning_500hpa

UPDATE:
    Xin Zhang:
       2022-05-19: Basic version
'''

import os
import numpy as np
import pandas as pd
import logging
import xarray as xr
from scipy import stats
from netCDF4 import Dataset
from s5p_lnox_utils import Config
from functools import partial
from multiprocessing import Pool
from pyresample import kd_tree
from pyresample.geometry import GridDefinition, SwathDefinition
from pyresample.bucket import BucketResampler

# Choose the following line for info or debugging:
logging.basicConfig(level=logging.INFO)
# logging.basicConfig(level=logging.DEBUG)

lon_resolution = 0.1
lat_resolution = 0.1
lon_bnd = np.arange(-180, 180+lon_resolution, lon_resolution)
lat_bnd = np.arange(70, 90+lat_resolution, lat_resolution)
lon_center = np.convolve(lon_bnd, np.ones(2), 'valid') / 2 
lat_center = np.convolve(lat_bnd, np.ones(2), 'valid') / 2 


def resample_data(filename, case, swaths, arctic_grid, tau=6):
    """Calculate production efficiency

    t0: time of reference swath
    t1: time of selected swath
    """
    res = []
    res_lno2 = []
    res_lno2_max = []
    res_lno2_sum = []
    res_lno2_vis = []
    res_lno2_vis_max = []
    res_lightning = []
    res_lightning_500hpa = []

    for index, swath in enumerate(swaths):
        logging.info(f'Processing {swath}')

        # load data
        ds_s5p = xr.open_dataset(filename, group=case+'/'+swath+'/S5P')
        ds_lightning = xr.open_dataset(filename, group=case+'/'+swath+'/Lightning')
        lon = ds_s5p['longitude']
        lat = ds_s5p['latitude']
        area = ds_s5p['area']
        no2 = ds_s5p['nitrogendioxide_tropospheric_column']*area
        lno2 = ds_s5p['lno2']*area
        lno2_vis = ds_s5p['lno2vis']*area

        # resample data to grid
        # bucket resample only works for AreaDefinition
        #lno2_resample = BucketResampler(arctic_grid, lon, lat).get_average(lon2)
        #lno2_vis_resample = BucketResampler(arctic_grid, lon, lat).get_average(lon2_vis)

        # something wrong with nearest
        #swath_tropomi = SwathDefinition(lons=lon, lats=lat)
        #
        #lno2_resample = xr.DataArray(kd_tree.resample_nearest(swath_tropomi, lno2.values,
        #                                                    arctic_grid, radius_of_influence=50000, epsilon=0.5),
        #                        dims=['latitude', 'longitude'], coords=[lat_center, lon_center]).rename('lno2')

        #lno2_vis_resample = xr.DataArray(kd_tree.resample_nearest(swath_tropomi, lno2_vis.values,
        #                                                    arctic_grid, radius_of_influence=50000, epsilon=0.5),
        #                        dims=['latitude', 'longitude'], coords=[lat_center, lon_center]).rename('lno2vis')


        lno2_resample = stats.binned_statistic_2d(lon.values.ravel(), lat.values.ravel(), lno2.values.ravel(), \
                                                  np.nanmean, bins=[lon_bnd,lat_bnd]).statistic
        # different unit (mol m-2) for comparison with other emissions later
        lno2_resample_max = stats.binned_statistic_2d(lon.values.ravel(), lat.values.ravel(), ds_s5p['lno2'].values.ravel(), \
                                                  np.nanmax, bins=[lon_bnd,lat_bnd]).statistic
        lno2_resample_sum = stats.binned_statistic_2d(lon.values.ravel(), lat.values.ravel(), lno2.values.ravel(), \
                                                  np.nansum, bins=[lon_bnd,lat_bnd]).statistic
        #lno2_vis_resample = stats.binned_statistic_2d(lon.values.ravel(), lat.values.ravel(), lno2_vis.values.ravel(), \
        #                                          np.nanmean, bins=[lon_bnd,lat_bnd]).statistic
        #lno2_vis_resample_max = stats.binned_statistic_2d(lon.values.ravel(), lat.values.ravel(), ds_s5p['lno2vis'].values.ravel(), \
        #                                          np.nanmax, bins=[lon_bnd,lat_bnd]).statistic

        lightning_resample = stats.binned_statistic_2d(ds_lightning['longitude'].values, ds_lightning['latitude'].values, None, \
                'count', bins=[lon_bnd,lat_bnd]).statistic
        lightning_resample_500hpa = stats.binned_statistic_2d(ds_lightning['longitude_pred'].sel(level=500).values, \
                            ds_lightning['latitude_pred'].sel(level=500).values, None, \
                            'count', bins=[lon_bnd,lat_bnd]).statistic

        # save as DataArray
        lno2_resample = xr.DataArray(lno2_resample, dims=['longitude', 'latitude'], coords=[lon_center, lat_center]).rename('lno2')
        lno2_resample_max = xr.DataArray(lno2_resample_max, dims=['longitude', 'latitude'], coords=[lon_center, lat_center]).rename('lno2_max')
        lno2_resample_sum = xr.DataArray(lno2_resample_sum, dims=['longitude', 'latitude'], coords=[lon_center, lat_center]).rename('lno2_sum')
        #lno2_vis_resample = xr.DataArray(lno2_vis_resample, dims=['longitude', 'latitude'], coords=[lon_center, lat_center]).rename('lno2vis')
        #lno2_vis_resample_max = xr.DataArray(lno2_vis_resample_max, dims=['longitude', 'latitude'], coords=[lon_center, lat_center]).rename('lno2vis_max')
        lightning_resample = xr.DataArray(lightning_resample, dims=['longitude', 'latitude'], coords=[lon_center, lat_center]).rename('lightning')
        lightning_resample = lightning_resample.where(lightning_resample!=0)
        lightning_resample_500hpa = xr.DataArray(lightning_resample_500hpa, dims=['longitude', 'latitude'], coords=[lon_center, lat_center]).rename('lightning_500hpa')
        lightning_resample_500hpa = lightning_resample_500hpa.where(lightning_resample_500hpa!=0)

        res_lno2.append(lno2_resample)
        res_lno2_max.append(lno2_resample_max)
        res_lno2_sum.append(lno2_resample_sum)
        #res_lno2_vis.append(lno2_vis_resample)
        #res_lno2_vis.append(lno2_vis_resample_max)
        res_lightning.append(lightning_resample)
        res_lightning_500hpa.append(lightning_resample_500hpa)
        logging.info(f'Finish processing {swath}')

    output_lno2 = xr.concat(res_lno2, dim='swath').assign_coords(swath=swaths)
    output_lno2.attrs['units'] = 'mol'
    output_lno2_max = xr.concat(res_lno2_max, dim='swath').assign_coords(swath=swaths)
    output_lno2_max.attrs['units'] = 'mol m-2'
    output_lno2_sum = xr.concat(res_lno2_sum, dim='swath').assign_coords(swath=swaths)
    output_lno2_sum.attrs['units'] = 'mol'
    #output_lno2_vis = xr.concat(res_lno2_vis, dim='swath').assign_coords(swath=swaths)
    output_lightning = xr.concat(res_lightning, dim='swath').assign_coords(swath=swaths)
    output_lightning_500hpa = xr.concat(res_lightning_500hpa, dim='swath').assign_coords(swath=swaths)

    return xr.merge([output_lno2, output_lno2_max, output_lno2_sum, output_lightning, output_lightning_500hpa])


def process_data(filename, arctic_grid, case):
    ds_nc = Dataset(filename)
    # get the group names of swath inside Case
    swaths = list(sorted(ds_nc[case].groups.keys()))
    ds_resample = resample_data(filename, case, swaths, arctic_grid)

    return ds_resample


def main():
    #filename = os.path.join(data_dir, 'S5P_LNO2_bak.nc')
    #filename = os.path.join(data_dir, 'S5P_LNO2_tmp.nc')
    filename = os.path.join(data_dir, 'S5P_LNO2_production.nc')
    ds_nc = Dataset(filename)

    # define the arctic grid
    lons, lats = np.meshgrid(lon_center, lat_center)
    arctic_grid = GridDefinition(lons=lons, lats=lats)

    # get the group names of Cases
    cases = list(sorted(ds_nc.groups.keys()))

    func = partial(process_data, filename, arctic_grid)
    #with Pool(processes=int(cfg['num_pool'])) as pool:
    with Pool(processes=8) as pool:
        ds = xr.merge(pool.map(func, cases))
        #output = pool.map(func, cases)
        pool.close()
        pool.join()

    #ds = ds.mean(dim='swath', skipna=True)

    # set encoding
    comp = dict(zlib=True, complevel=7)
    enc = {var: comp for var in ds.data_vars}

    # export file
    savename = f'{savedir}/S5P_LNO2_grid.nc'
    print(f'Saved to {savename}')
    ds.to_netcdf(path=f'{savename}',
                 engine='netcdf4',
                 encoding=enc)


if __name__ == '__main__':
    # read config file
    cfg = Config('settings.txt')
    logging.info(cfg)

    data_dir = cfg['output_data_dir']
    savedir = cfg['output_data_dir']

    main()
